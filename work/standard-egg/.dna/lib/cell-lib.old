#!/bin/bash

type -t spawn_update_process >/dev/null && return 0

SIMPLETON_EXTENSIONS=${SIMPLETON_EXTENSIONS:-$SIMPLETON_REPO/..}

# don't let other users read any files written by these scripts
umask 0077

readonly failed_but_can_retry=2 skip=2 somethings_wrong=1 everythings_fine=0

parallel_default=t 
[[ $debug == t ]] && parallel_default=f
parallel_execution=${parallel_execution:-${par:-$parallel_default}}

maybe_update() {
# checking this outside of the spawn process itself, to avoid needless
#   forking of subshells in a large percentage of cases
local cube_needs_update

get_cube_needs_update || return 1
if [[ $cube_needs_update == t ]]; then
  ( spawn_loop=once spawn_update_process $subject ) || return 1
fi
return 0
}

# should always run in a subshell
# should check whether update is needed before running this
spawn_update_process() {
local subject=$(realpath $1) || return 1
spawn_loop=${spawn_loop:-${loop:-until_idle}}
subs_fetched=f
focus_on $subject || return 1

trace $log_info "Spawning update process for $short_cube ($spawn_loop)"
begin_function

  spawn_pre || fail

  begin_loop

    something_was_changed=f
    something_is_locked=f

    update_cube || fail
    cube_update_subs || fail

    if [[ $spawn_loop == once ]]; then
      succeed
    fi

    if [[ $something_was_changed == t ]]; then
      current_pause=$min_pause
    elif [[ 
      $something_is_locked == t 
      || $spawn_loop == forever 
      ]]; then
      # do not exit until all sub cube processes have completed
      # because req folder must be completed before starting a new
      # spawn and wiping out the old requests
      let 'current_pause *= 2'
      [[ $current_pause -gt $max_pause ]] && current_pause=$max_pause
    fi

    pause_time=$(echo "scale=3; $current_pause/1000" | bc)
    trace $log_trace "Sleeping for $pause_time seconds"
    sleep $pause_time || fail

  end_loop

  spawn_post || fail

end_function
handle_return
}

cube_update_subs() {
trace $log_info "Updating subs"
begin_function
  if [[ ${subs_fetched:-f} == f ]]; then
    sub_cubes=( )
    if [[ -f $cube_cyto_path/sub-cubes ]]; then
      sub_cubes=( $(<$cube_cyto_path/sub-cubes) )
    else
      find_sub_cubes $cube_path || fail
      local subs="${sub_cubes[*]}"
      subs=${subs// /$NL}
      echo "$subs" >$cube_cyto_path/sub-cubes || fail
    fi
    subs_fetched=t
  fi

  local parallel=f
  if [[ $parallel_execution == t && ${#sub_cubes[*]} -gt 1 ]]; then
    parallel=t
  fi

  local sub processes=

  begin_for sub in ${sub_cubes[*]}; doo
    get_cube_needs_update $sub || fail
    if [[ $cube_needs_update == t ]]; then
      if [[ $parallel == t ]]; then
        # recursive
        spawn_loop=once spawn_update_process $sub &
        processes+=" $!"
      else
        # recursive
        ( spawn_loop=once spawn_update_process $sub ) || fail
      fi
    fi
  end_for

  wait_for_sub_processes || fail

end_function
handle_return
}

# This will check the cells specified by the dim filters given. 
# If any cell matching the filter needs an update, this will return true
get_cube_needs_update() {
local cube_node_needs_update \
  fresh=${fresh:-} \
  remaining_batch_dims=( "${batch_dims[@]}" )
get_cube_node_needs_update $batch_path || return 1
cube_needs_update=$cube_node_needs_update
return 0
}

# inputs: remaining_batch_dims
get_cube_node_needs_update() {
begin_function_flat
  local -r node_path=$1 
  local try_subdivide=f
  cube_node_needs_update=f 

  # check node status
  local -r node_status_path=$node_path/status
  if [[ -d $node_status_path ]]; then
    get_needs_update $node_status_path || fail
    if [[ $needs_update=t  ]]; then
      try_subdivide=t
    fi
  else
    try_subdivide=t
  fi

  if [[ $try_subdivide == t ]]; then
    if [[ "${remaining_batch_dims:-}" \
       && -d $node_path/dim/$remaining_batch_dims \
       ]]; then
      branch_function=subdivide_needs_update \
        for_each_batch ${remaining_batch_dims[*]} || fail
    else
      cube_node_needs_update=t
    fi
  fi

end_function_flat
handle_return
}

subdivide_needs_update() {
begin_function_flat
  local -r node_status_path=$batch_path$batch_node/status
  if [[ ! -d $node_status_path ]]; then
    cube_node_needs_update=t
    finished=t
  else 
    get_needs_update $node_status_path || fail
    go_deeper=$needs_update
  fi
end_function_flat
handle_return
}

get_is_stale() {
begin_function_flat
  local -r node_status_path=$1 
  is_stale=t
  if [[ ! "$fresh" || "$fresh" == inf ]]; then
    is_stale=f
  elif [[ $fresh != 0 ]]; then
    local fresh_seconds
    convert_to_seconds $fresh fresh_seconds || fail
    local fresh_cutoff=$((EPOCHSECONDS-fresh_seconds))
    local out_timestamp=
    if [[ -f $node_status_path/oldest-update ]]; then
      out_timestamp=$(date -r $node_status_path/freshness +%s)
    fi
    if [[ "$out_timestamp" && $out_timestamp -ge $fresh_cutoff ]]; then
      is_stale=f
    fi
  fi
end_function_flat
handle_return
}

# returns sub_cubes
find_sub_cubes() {
local path=$1 folder
begin_function
  local folders_to_check=( $(find1 $path -type d -not -name '\.cyto') ) || fail
  begin_for folder in ${folders_to_check[*]}; doo
    if [[ -d $folder/.dna ]]; then
      sub_cubes+=( $folder )
    else
      # recursive
      find_sub_cubes $folder || fail
    fi
  end_for
end_function
handle_return
}

spawn_post() {
folder_to_unlock=$lock_path folder_unlock || return 1
untee_output
return 0
}

spawn_pre() {
begin_function

  if [[ "$cube_lock_path" ]]; then
    folder_to_lock=$cube_lock_path timeout= folder_lock || {
      err "Failed to obtain lock for $short_cube"
      fail
      }
  fi

  if [[ "$cube_log_path" ]]; then
    tee_output_to $cube_log_path/update-log-current || fail
  fi

  strategies=${strategies:-$default_strategies}
  expand_strategies || fail

  gather_dims || fail
  if [[ "$localize_dim_vars" ]]; then
    eval "$localize_dim_vars" || fail
  fi
  
  fresh=${fresh2:-${fresh:-$default_fresh}}

end_function
handle_return
}

tee_output_to() {
local target=$1
exec 1> >(tee "$target")
exec 2> >(tee -a "$target")
eval "exec $fd_trace> >(tee -a '$target')"
}

untee_output() {
exec 1>&$fd_original_out
exec 2>&$fd_original_err
eval "exec $fd_trace>&$fd_original_trace"
}

update_cube() {
trace $log_info "Handling cube local update for $short_cube"
begin_function

  if [[ "$cell_expiration" && -d $batch_path ]]; then
    trace $log_trace "Deleting cached data older than $cell_expiration"
    local expiration_minutes
    convert_to_seconds $cell_expiration expiration_minutes || fail
    let expiration_minutes/=60
    find1 $batch_path -mmin +$expiration_minutes -exec rm -r \{\} + || fail
  fi

  if [[ "$req_path" ]]; then
    local req reqs
    # rotate request batch
    if [[ -d $req_path ]]; then
      reqs=$req_path/*
      if [[ "$reqs" != "$req_path/*" ]]; then
        # put the incomplete requests back in queue
        if [[ ! -d $req_path.new ]]; then
          mkdir $req_path.new || fail
        fi
        mv -n $req_path/* $req_path.new/ || fail
      fi
      rm -r $req_path || fail
    fi

    # nothing should create the req.new folder except for the cell itself
    # if .new folder doesn't exist, then external cells can't make requests
    if [[ -d $req_path.new ]]; then
      # try and do these two things with the least possible time between them
      #   to minimize chance of race conditions. This should provide a reasonable
      #   compromise between simplicity and stability. 
      mv $req_path.new $req_path && mkdir $req_path.new || fail
    else
      mkdir $req_path.new || fail
    fi

    # loop over requests
    reqs=( $req_path/* )
    local processes=
    if [[ "$reqs" != "$req_path/*" ]]; then

      # define this function if custom req aggregation is needed
      if type aggregate_reqs &>/dev/null; then
        # modifies reqs array 
        aggregate_reqs || fail
      fi

      local parallel=f
      if [[ $parallel_execution == t && ${#reqs[*]} -gt 1 ]]; then
        parallel=t
      fi

      begin_for req in ${reqs[*]}; doo
        if [[ $parallel == t ]]; then
          handle_local_update_for_req "$req" &
          processes+=" $!"
        else
          ( handle_local_update_for_req "$req" ) || fail
        fi
      end_for

    fi

    # all updates should complete before moving on to static subs
    wait_for_sub_processes || fail

    rm -r $req_path || fail

  else
    # no req_path
    handle_local_update_by_batch || fail
  fi

  if [[ -f $dna_path/after-update ]]; then
    source $dna_path/after-update || fail
  fi

end_function
handle_return
}

expand_strategies() {
local new_strategies=
for strategy in $strategies; do
  case $strategy in
    cached|c)
      new_strategies+=" cached"
    ;;
    reliable|reliability|r)
      new_strategies+=" reliable"
    ;;
    latency|l)
      new_strategies+=" latency"
    ;;
    throughput|t)
      new_strategies+=" throughput"
    ;;
    crt)
      new_strategies+=" cached reliable throughput"
    ;;
    crl)
      new_strategies+=" cached reliable latency"
    ;;
    *)
      err "Invalid strategy: $strategy"
      return 1
    ;;
  esac
done
strategies=${new_strategies# }
}

# always run in a subshell
handle_local_update_for_req() {
local req=$1
begin_function

  source $req || fail

  handle_local_update_by_batch || fail

  rm $req || fail

end_function
handle_return
}

handle_local_update_by_batch() {
begin_function_flat

  if [[ ! "$batch_dims" ]]; then
    batch_id=( )
    ( batch_update ) || fail
  else
    leaf_function=batch_update for_each_batch "${batch_dims[@]}" || fail
  fi

end_function_flat
handle_return
}

# inputs: 
#   $1 = batch path
#   batch_values
batch_update_direct() {
local batch=$1
local cube=${batch%/.cyto/batch/*}
focus_on $cube || return 1
local batch_values=( )
if [[ -f $batch/batch_values ]]; then
  source $batch/batch_values || return 1
fi
( batch_update ) || return 1
}

# always run in subshell
# executes update of a single batch 
batch_update() {
begin_function_flat
  
  setup_batch_path_vars || fail
  batch_validate; local result=$?
  if [[ $result -ne 0 ]] ; then
    case $result in
      $skip)
        # Skip this batch since dimension combination doesn't exist
        succeed
      ;;
      *)
        # Batch dimensions aren't valid
        fail1
      ;;
    esac
  fi

  if [[ "$batch_up_path" ]]; then
    if [[ ! -d $batch_up_path || $cube_up_path -nt $batch_up_path ]]; then
      if [[ -e $batch_up_path.new ]]; then
        rm -rf $batch_up_path.new || fail
      fi
      mkdir $batch_up_path.new || fail
      batch_setup_up $cube_up_path $batch_up_path.new || fail
      if [[ $batch_up_path ]]; then
        rm -rf $batch_up_path || fail
      fi
      mv $batch_up_path.new $batch_up_path || fail
    fi
  fi

  if [[ "$batch_down_path" ]]; then
    if [[ ! -d "$batch_down_path" || $cube_down_path -nt $batch_down_path ]]; then
      if [[ -e $batch_down_path.new ]]; then
        rm -rf $batch_down_path.new || fail
      fi
      mkdir $batch_down_path.new || fail
      batch_setup_x_deps down $cube_down_path $batch_down_path.new || fail
      if [[ $batch_down_path ]]; then
        rm -rf $batch_down_path || fail
      fi
      mv $batch_down_path.new $batch_down_path || fail
    fi
  fi

  if [[ $force_update == f && "$batch_status_path" ]]; then
    get_needs_update $batch_status_path || fail
    if [[ $needs_update == f ]]; then
      succeed
    fi
  fi

  local start_time=$EPOCHSECONDS
  if [[ "$batch_status_path" ]]; then
    touch $batch_status_path/update_started_but_not_done || fail
  fi

  local consecutive_failures=${consecutive_failures:-0} \
        upstream_changed=f batch_was_changed=f \
        update_successful=f

  if [[ "$batch_up_path" ]]; then
    new_stage update-deps || fail
    batch_update_deps || fail
  fi

  batch_pre_update || fail
  batch_execute_update || fail
  if [[ $postvalidate == t ]] && type batch_read_external &>/dev/null; then
    if [[ ! "${value:-}" ]]; then
      err "batch_read_external is defined, but value was not given, so we can't use it."
      fail1
    fi
    batch_read_external || fail
    if [[ "$result" != "$value" ]]; then
      err "update did not correctly change external value: $result != $value"
      fail
    fi
  fi
  batch_post_update || fail

end_function_flat
handle_return
}

get_needs_update() {
begin_function_flat

  local -r node_status_path=$1
  needs_update=f

  if [[ ! -d $node_status_path
     || -e $node_status_path/outdated 
     || ! -e $node_status_path/update_succeeded
     || $node_status_path/update_requested -nt $node_status_path/update_started ]]; then
    needs_update=t
  else
    get_is_stale $node_status_path || fail
    if [[ $is_stale == t ]]; then
      needs_update=t
    fi
  fi

  if [[ $needs_update=t && ${prevalidate:-f} == t ]] && type batch_read_external &>/dev/null; then
    if [[ ! "${value:-}" ]]; then
      err "batch_read_external is defined, but value was not given, so we can't use it."
      fail1
    fi
    batch_read_external || fail
    if [[ "$result" == "$value" ]]; then
      needs_update=f
    fi
  fi

end_function_flat
handle_return
}

batch_post_update() {

begin_function

  new_stage complete || fail
  local end_time=$EPOCHSECONDS
  local duration_of_update=$((end_time-start_time))

  local avg_duration_short=${avg_duration_short:-$duration_of_update} \
        avg_duration_long=${avg_duration_long:-$duration_of_update} \
        avg_failure_rate_short=${avg_failure_rate_short:-0} \
        avg_failure_rate_long=${avg_failure_rate_long:-0} \
        max_duration_short=${max_duration_short:-0} \
        max_duration_short_age=${max_duration_short_age:-0} \
        max_duration_long=${max_duration_long:-0} \
        max_duration_long_age=${max_duration_long_age:-0} \
        sample_count=${sample_count:-0} \
        update_id=1000 

  read_persist_file || fail

  if [[ $update_successful == t ]]; then

    trace $log_info "Update successful."

    if [[ "$batch_out_path" && -d "$batch_out_path.new" ]]; then

      local batch_was_changed
      if [[ -d "$batch_out_path" ]]; then
        batch_was_changed=f
        if files_are_different -r "$batch_out_path" "$batch_out_path.new" >/dev/null; then
          [[ -d "$batch_out_path.old" ]] && rm -r "$batch_out_path.old"
          mv "$batch_out_path" "$batch_out_path.old" || fail
          mv "$batch_out_path.new" "$batch_out_path" || fail
          if [[ ! "$debug_path" ]]; then
            rm -r "$batch_out_path.old" || fail
          fi
          batch_was_changed=t
        else
          rm -r "$batch_out_path.new" || fail
        fi
      else # batch_out_path doesn't exist
        mv "$batch_out_path.new" "$batch_out_path" || fail
        batch_was_changed=t
      fi

      if [[ $ignore_fresh == f && "$batch_status_path" ]]; then
        touch -d @$start_time $batch_status_path/update_started || fail
      fi

    fi

    if [[ "$batch_tmp_path" && -d "$batch_tmp_path" && ! "$batch_debug_path" ]]; then
      rm -r "$batch_tmp_path" || fail
    fi

    if [[ "$batch_status_path" ]]; then
      mv $batch_status_path/update_started_but_not_done $batch_status_path/update_started || fail
    fi

    consecutive_failures=0

    if [[ $debugging == f ]]; then
      update_max_duration max_duration_short 10
      update_max_duration max_duration_long 100
      let 'avg_duration_short = (avg_duration_short * 9 + duration_of_update * 1000) / 10'
      let 'avg_duration_long = (avg_duration_long * 99 + duration_of_update * 1000) / 100'
    fi

    let 'avg_failure_rate_short = (avg_failure_rate_short * 9) / 10'
    let 'avg_failure_rate_long = (avg_failure_rate_long * 99) / 100'
    let sample_count++

  else

    trace $log_warn "Update of $short_cube cube $batch_id failed."
    if [[ $local_failure == t ]]; then
      let consecutive_failures++
      let 'avg_failure_rate_short = (avg_failure_rate_short * 9 + 1000) / 10'
      let 'avg_failure_rate_long = (avg_failure_rate_long * 99 + 1000) / 100'
      let sample_count++
    fi

  fi

  if [[ "$batch_status_path" ]]; then
    write_persist_file || fail
  fi

  if [[ "$batch_log_path" ]]; then

    local success_string=good
    [[ $update_successful == f ]] && success_string=bad
    echo "update_id=$update_id start=$start_time duration=$duration_of_update from=$called_from" \
      "result=$success_string changed=$batch_was_changed" >>$batch_log_path/history || fail

    untee_output || fail

    if [[ "$debug_path" ]]; then
      mv $batch_log_path/update-log-id-* $debug_path/ &>/dev/null
      mv $batch_log_path/stage-timing-id-* $debug_path/ &>/dev/null
    else
      rm $batch_log_path/update-log-id-* &>/dev/null
      rm $batch_log_path/stage-timing-id-* &>/dev/null
    fi

    mv $batch_log_path/update-log-current $batch_log_path/update-log-id-$update_id || fail
    ln -f $batch_log_path/update-log-id-$update_id $batch_log_path/update-log-last-$success_string || fail
    mv $batch_log_path/stage-timing-current $batch_log_path/stage-timing-id-$update_id || fail
    ln -f $batch_log_path/stage-timing-id-$update_id $batch_log_path/stage-timing-last-$success_string || fail

  fi

  if [[ $update_successful == t ]]; then
    if [[ -f $batch_status_path/upstream-changed ]]; then
      rm $batch_status_path/upstream-changed || fail
    fi
    if [[ $batch_was_changed == t ]]; then
      trace $log_trace2 "Notifying downstream cells of change"
      notify_downstream_of_change $batch_path || fail
    fi
    if [[ "$batch_status_path" ]]; then
      touch $batch_status_path/updated || fail
    fi
  fi

end_function
handle_return

}

notify_downstream_of_change() {
begin_function
  local cell=$1 down_cell down_cells
  if [[ "$down_path" && -d $down_path ]]; then
    down_cells=$(find1 $cell/.cyto/down); or_fail
    begin_for down_cell in $down_cells; doo
      if [[ ! -e $down_cell ]]; then
        trace $log_trace "Removing broken link: $down_cell"
        rm $down_cell || fail
      elif [[ ! -f $down_cell/status/upstream-changed ]]; then
        local nice_down_cell=
        should_trace && nice_down_cell=$(realpath $down_cell)
        trace $log_trace2 "Notifying ${nice_down_cell#$top_path} of change"
        local status_path=$down_cell/.cyto/status
        if [[ ! -d $status_path ]]; then
          mkdir -p $status_path || fail
        fi
        touch $status_path/upstream-changed || fail
        local parent_cell
        get_parent_cell $(realpath $down_cell) || fail
        if [[ "$parent_cell" ]]; then
          local min_fresh_file=$parent_cell/.cyto/status/min-upstream-freshness
          if [[ -f $min_fresh_file ]]; then
            rm $min_fresh_file || fail
          fi
          # recursive
          notify_downstream_of_change $down_cell || fail
        fi
      fi
    end_for
  fi
end_function
handle_return
}

get_parent_cell() {
local cell=$1
parent_cell=${cell%/*}
if [[ $parent_cell != "$top_path/"* ]]; then
  parent_cell=
  return 0
elif [[ -d $parent_cell/.dna ]]; then
  return 0
else
  get_parent_cell $parent_cell || return 1
fi
return 0
}

write_persist_file() {
echo "\
update_id=$update_id
cooldown_delay=${cooldown_delay:-0}
consecutive_failures=$consecutive_failures
avg_duration_short=$avg_duration_short
avg_duration_long=$avg_duration_long
avg_failure_rate_short=$avg_failure_rate_short
avg_failure_rate_long=$avg_failure_rate_long
max_duration_short=$max_duration_short
max_duration_short_age=$max_duration_short_age
max_duration_long=$max_duration_long
max_duration_long_age=$max_duration_long_age
sample_count=$sample_count
" >$batch_status_path/persist
}

update_max_duration() {
local var=$1
local window=$2
local age_var=${var}_age
if [[ $duration_of_update -gt ${!var} ]]; then
  eval "$var=$duration_of_update; $age_var=0"
elif [[ ${!age_var} -gt $window ]]; then
  eval "let $var=($var+$duration_of_update)/2; $age_var=0"
else
  eval "let $age_var++"
fi
}

batch_execute_update() {
trace $log_info "Executing update"
begin_function

  local gen_function
  begin_for gen_function in $generators; doo
    $gen_function || fail
  end_for

  if type execute_update &>/dev/null; then
    new_stage execute-update || fail
    local rc delay=$retry_delay

    for ((retry=0; retry < retry_max; retry++)); do

      execute_update; rc=$?

      case $rc in
        $failed_but_can_retry)
          [[ $retry -lt $((retry_max-1)) ]] && trace $log_info "execute_update failed. Will retry"
        ;;
        $everythings_fine)
          update_successful=t
          break
        ;;
        *)
          trace $log_warn "execute_update returned $rc"
          break
        ;;
      esac

      trace $log_info "Waiting $delay seconds before retrying."
      sleep $delay
      let 'delay *= retry_scale'

    done

  else
    update_successful=t
  fi

  if [[ $update_successful == f ]]; then
    local_failure=t
  fi

end_function
handle_return
}

batch_pre_update() {

begin_function

  new_stage begin-update || fail

  if [[ -d $batch_out_path.new ]]; then 
    rm -r $batch_out_path.new || fail
  fi
  if [[ "$batch_out_path" ]]; then
    mkdir $batch_out_path.new || fail
  fi

  if [[ "$batch_status_path" ]]; then

    read_persist_file || fail

    if [[ "${update_id:-}" ]]; then
      let update_id++
    fi

    maybe_apply_cooldown || fail

  fi

  if [[ "$batch_up_path" ]]; then
    local cell_up_dep
    if [[ ! -d $batch_up_path ]]; then
      err "Internal error: invalid batch_up_path=$batch_up_path"
      stack_trace
      fail1
    fi

    local deps=$(find1 $batch_up_path); or_fail
    begin_for cell_up_dep in $deps; doo
      handle_cell_reply $cell_up_dep || fail
    end_for
  fi

end_function
handle_return

}

# inputs: $1 (cell up/{dep} folder)
handle_cell_reply() {
local dep=$1 cell multi dep2
if [[ $dep == ${dep%\?} ]]; then
  # not multipath
  handle_cell_reply_cells $dep || return 1
else
  # multipath dep
  for dep2 in $(find1 $dep); do or_fail
    handle_cell_reply_cells $dep2 || return 1
  true; done
fi
return 0
}

handle_cell_reply_cells() {
local dep=$1
local cells=$(find1 $dep); or_fail
for cell in $cells; do 
  if [[ -f $cell/.cyto/out/context ]]; then
    source $cell/.cyto/out/context || return 1
  fi
  if [[ $cell/.cyto/out -nt $batch_out_path ]]; then
    upstream_changed=t
  fi
done
return 0
}

maybe_apply_cooldown() {
begin_function
  # If cell recently failed, wait until cooldown period is complete
  if [[ $consecutive_failures -gt 0 ]]; then
    get_cooldown_delay || fail
    if [[ $cooldown_delay -gt 0 ]]; then
      trace $log_warn "Too many errors have occurred, waiting for cooldown period of $cooldown_delay seconds"
      new_stage cooldown || fail
      sleep $cooldown_delay
    fi
  else
    cooldown_delay=1
  fi
end_function
handle_return
}

read_persist_file() {
if [[ "$batch_status_path" && -e $batch_status_path/persist ]]; then
  source $batch_status_path/persist || fail
fi
return 0
}

batch_validate() {

begin_function

  if ! are_batch_params_valid; then
    err "Invalid parameters."
    fail1
  fi

  if skip_batch; then
    trace $log_trace "Skipping batch because of mismatching batch id: $batch_id"
    return_value=$skip
    break_out=t
    break
  fi

end_function
handle_return

}

new_stage() {
local stage=$1
if [[ "${previous_stage:-}" ]]; then
  trace $log_trace2 "Finished stage $previous_stage" \
    "in $(echo "$EPOCHSECONDS - $stage_start_time" | bc) seconds"
fi
[[ "$batch_log_path" ]] && echo "$stage $EPOCHSECONDS" >>"$batch_log_path/stage-timing-current"
trace $log_trace2 "Starting stage $stage"
stage_start_time=$EPOCHSECONDS
previous_stage=$stage
}

batch_update_deps() {
trace $log_trace "Updating upstream cubes of $short_cube"
begin_function

  local dep 
  local parallel=f processes=

  local parallel_deps=( $(
    find1 "$batch_up_path" -type d \
      -not -regex "$batch_up_path/[0-9]+-.*" \
      | sort) ) || {
    err "find failed"
    fail1
  }

  local serial_deps=( $(
    find1 "$batch_up_path" -type d \
      -regex "$batch_up_path/[0-9]+-.*" \
      | sort) ) || {
    err "find failed"
    fail1
  }

  local total_parallel=${#parallel_deps[*]}
  local total=$total_parallel
  [[ "${serial_deps:-}" ]] && let total++

  if [[ $total -gt 1 && $parallel_execution == t ]]; then
    parallel=t
    wait_for_low_load || fail
  fi

  begin_for dep in ${parallel_deps[*]}; doo
    local dep_name=${dep##*/}
    if [[ $parallel == t ]]; then
      update_dep "$dep" &
      processes+=" $!"
    else
      ( update_dep "$dep" ) || fail
    fi
  end_for

  if [[ $parallel == t ]]; then
    batch_update_deps_serial &
    processes+=" $!"
  else
    batch_update_deps_serial || fail
  fi

  # In this case we want to wait for the dependencies to be completed before
  # advancing because we can't execute the update until then. 
  wait_for_sub_processes || fail

end_function
handle_return
}

update_dep_multipath() {
trace $log_trace "Updating multipath upstream dependency: ${dep##*/}"
begin_function

end_function
handle_return
}

batch_update_deps_serial() {
for dep in ${serial_deps[*]}; do
  ( update_dep "$dep" ) || return 1
done
return 0
}

# guaranteed to run in sub process
update_dep() {
local dep=$1 choice multipath=f
local choices=( $dep ) 
begin_function

  local dep_name=${dep##*/}
  if [[ $dep == *\? ]]; then
    multipath=t
    update_dep_handle_multipath || fail
  fi

  local chosen= failed new_fresh=${fresh2:-} new_fresh2=
  if [[ $ignore_fresh == t ]]; then
    new_fresh=$fresh new_fresh2=${fresh2:-}
  fi

  # attempt update of each option, until one succeeds
  view= fresh=$new_fresh fresh2=$new_fresh2 \
    called_from=$short_cube parent= 
  begin_for choice in ${choices[*]}; doo
    failed=f
    handle_member_override $choice || fail
    make_request $choice || fail
    # recursive
    update_dep_spawn_choice $choice || failed=t
    if [[ $failed == f ]]; then
      chosen=$choice
      break
    fi
  end_for

  if [[ ! "$chosen" ]]; then
    trace $log_warn "Failed to update dependency: $dep"
    fail1
  fi

  if [[ $multipath == t ]]; then
    local chosen_name=${chosen##*/} 
    if [[ $chosen_name =~ ^[0-9]+-(.*) ]]; then
      chosen_name=${BASH_REMATCH[1]}
    fi
    local target=$batch_up_path/${dep_name%\?}
    safe_link $batch_up_path/$dep_name/$chosen_name $target || fail
    trace $log_info "Chose $chosen_name for $dep"
  fi

end_function
handle_return
}

update_dep_spawn_choice() {
begin_function_flat
  local sub_choices=( $(find1 $choice -not -name only | sort) ) || fail
  local sub_choice
  begin_for sub_choice in "${sub_choices[@]}"; doo
    batch_update_direct $(realpath $sub_choice) || fail
  end_for
end_function_flat
handle_return
}

update_dep_handle_multipath() {
begin_function_flat

  local OIFS=$IFS
  IFS=$NL 
  choices=( $(find1 $dep | sort) ) || fail
  IFS=$OIFS
  local choice_count=${#choices[*]} result results

  if [[ $choice_count == 0 ]]; then
    err 'No choices available for $dep'
    fail1
  elif [[ $choice_count -gt 1 ]]; then
    local i choice_path choice_name choice_cell cells 

    results=( )
    for ((i=0; i<choice_count; i++)); do
      results[$i]=
    done

    update_dep_compute_strategies || fail
    for ((i=0; i<choice_count; i++)); do
      results[$i]+=" ${choices[$i]}$NL"
    done
    
    OIFS=$IFS IFS=$NL choices=( $(echo "${results[*]}" | sort) ) IFS=$OIFS

    # avoid strategy starvation by occasionally allowing the underdog to be on top
    if [[ $((RANDOM % 1000)) -lt $shuffle_chance ]]; then
      local c=${#choices[*]}
      let c--
      OIFS=$IFS IFS=$NL choices=( ${choices[-1]} ${choices[*]:0:$c} ) IFS=$OIFS
      trace $log_trace "Shuffled strategies"
    fi

    trace $log_trace "Strategy results:"
    for ((i=0; i<choice_count; i++)); do
      choice=${choices[$i]}
      trace $log_trace "$choice"
      choices[$i]="${choice##* }"
    done

  fi

end_function_flat
handle_return
}

update_dep_compute_strategies() {
local strategy
trace $log_trace "Computing strategies: $strategies"
begin_function
  begin_for strategy in $strategies; doo
    if type strategy_$strategy &>/dev/null; then
      begin_for ((i=0; i<choice_count; i++)); doo

        choice="${choices[$i]}"
        choice_name=${choice##*/}
        if [[ $choice_name =~ ^[0-9]+-(.*) ]]; then
          choice_name=${BASH_REMATCH[1]}
        fi

        if [[ ! -d $batch_up_path/$dep_name/$choice_name ]]; then
         err "Invalid choice: $choice_cell"
         fail1
        fi

        choice_cell=$batch_up_path/$dep_name/$choice_name/only
        if [[ ! -d $choice_cell ]]; then
          local cells=( $(find1 ${choice_cell%/*}) )
          if [[ ${#cells[*]} -lt 2 ]]; then
            err "Invalid batch_up_path: $choice_cell, will attempt to repair."
            err "Rerun this update to see if it worked."
            rm -r $batch_up_path || fail
            fail1
          else
            incomplete "Can't handle multiple cells in a multi-path dependency yet: $choice_cell"
          fi
        fi

        result=${results[$i]}
        strategy_$strategy || fail
        results[$i]=$result

      end_for
    else
      err "Missing strategy function: strategy_$strategy"
      fail1
    fi
  end_for
end_function
handle_return
}

# Does a given dependency already have fresh data?
# input: result choice_cell
# output: result
strategy_cached() {
trace $log_trace "Calculating cached score for $choice"
begin_function

  local needs_update 
  local $path_vars
  setup_cube_path_vars $choice_cell || fail
  does_cell_need_update $choice_cell || fail

  if [[ $needs_update == t ]]; then
    result+=" 1"
  else
    result+=" 0"
  fi

end_function
handle_return
}

# Computes the error rate of a given dependency?
# input: result choice_cell
# output: result
strategy_throughput() {
trace $log_trace "Calculating throughput score for $choice"
begin_function

  local avg_duration=0
  local status_path=$choice_cell/.cyto/status

  if [[ -e $status_path/persist ]]; then
    source $status_path/persist || fail
  fi

  avg_duration=${avg_duration_long:-0}

  result+=" $(printf "%04d" $avg_duration)"

end_function
handle_return
}

# Computes the error rate of a given dependency?
# input: result choice_cell
# output: result
strategy_latency() {
trace $log_trace "Calculating latency score for $choice"
begin_function

  local max_duration=0
  local status_path=$choice_cell/.cyto/status

  if [[ -e $status_path/persist ]]; then
    source $status_path/persist || fail
  fi

  max_duration=${max_duration_long:-0}

  result+=" $(printf "%04d" $max_duration)"

end_function
handle_return
}

# Computes the error rate of a given dependency?
# input: result choice_cell
# output: result
strategy_reliable() {
trace $log_trace "Calculating reliable score for $choice"
begin_function

  local avg_fail_rate=0
  local status_path=$choice_cell/.cyto/status

  if [[ -e $status_path/persist ]]; then
    source $status_path/persist || fail
  fi

  avg_fail_rate=${avg_failure_rate_short:-0}

  result+=" $(printf "%04d" $avg_fail_rate)"

end_function
handle_return
}

make_request() {
local cube=$1; shift
local extra_vars=${*:-}
trace $log_trace "Requesting update for $short_cube"
begin_function

  [[ $cube_type == constant ]] && succeed
  if [[ ! "$req_path" ]]; then
    # loop over batches
    leaf_function=make_request_batch for_each_batch "${batch_dims[@]}" || fail
  else
    make_delayed_request || fail
  fi

end_function
handle_return
}

make_request_batch() {
get_batch_node
local batch_status_path=$batch_path$batch_node/status
if [[ -d $batch_status_path ]]; then
  touch $batch_status_path/update_requested || fail
fi
}

make_delayed_request() {
begin_function

  if [[ ! "$batch_path" ]]; then
    err "batch_path not set"
    fail1
  fi

  if [[ ! "$req_new_path" ]]; then
    err "req_new_path not set. make_delayed_request should be run after setup_cube_path_vars."
    fail1
  fi

  let delayed_requests++
  local retries_left=3 request_successful=f pause_time=250 pause_time_s=

  local dim dims= content value
  content="batch_path=$batch_path$NL"

  if [[ -d $dim_path ]]; then
    dims=$(find1 $cell/.dna/dim | sort); or_fail
    begin_for dim in $dims; doo
      dim=${dim##*/}
      if [[ $dim =~ ^[0-9]+-(.*) ]]; then
        dim=${BASH_REMATCH[1]}
      fi
      eval "value=\${$dim:-}"
      content+="$dim='$value'$NL"
    end_for
  fi

  local measures="${measures:-${measure:-}}"
  local measure new_value
  if [[ "$measures" ]]; then
    content+="measures='$measures'$NL"
    begin_for measure in $measures; doo
      eval "new_value=\${new_$measure:-}"
      if [[ "$new_value" ]]; then
        content+="new_$measure=$new_value$NL"
      fi
    end_for
  else
    if [[ "${new_value:-}" ]]; then
      content+="new_value='$new_value'$NL"
    fi
  fi

  local var
  begin_for var in $extra_vars; doo
    content+="$var=\"${!var}\"$NL"
  end_for

  local md5=$(echo "$content" | cksum -a md5 | awk '{ print $4 }')

  begin_while [[ $retries_left -gt 0 ]]; doo

    if [[ -d $req_new ]]; then
      echo "$content" >$req_new/$md5 || fail
      make_request_update_ancestors $(realpath $cell) || fail
      request_successful=t
      break
    fi

    let retries_left--
    let pause_time*=2
    pause_time_s=$(echo "scale=3; $pause_time/1000" | bc)
    trace $log_info "$req_new doesn't exist. Waiting $pause_time_s seconds before checking again."
    sleep $pause_time_s

  end_while

  if [[ $request_successful == f ]]; then
    err "New request folder doesn't exist, so can't create new requests: $req_new"
    fail1
  fi

end_function
handle_return
}

make_request_update_ancestors() {
local cell=$1
local status_path=$cell/.cyto/status

if [[ ! -d $status_path ]]; then
  mkdir -p $status_path || return 1
fi

if [[ ! -f $status_path/update_requested ]]; then
  touch $status_path/update_requested || return 1
  local parent_cell=
  get_parent_cell $cell || return 1
  if [[ "$parent_cell" ]]; then
    # recursive
    make_request_update_ancestors $parent_cell || return 1
  fi
fi

return 0
}

get_parent_cell() {
local cell=$1
parent_cell=${cell%/*}
if [[ $parent_cell != "$top_path/"* ]]; then
  parent_cell=
  return 0
elif [[ -d $parent_cell/.dna ]]; then
  return 0
else
  # recursive
  get_parent_cell $parent_cell || return 1
fi
}

batch_setup_up() {

local cube_up_path=$1 batch_up_path=$2
trace $log_info "Setting up dependency path for batch"

begin_function

  local dep_name target group
  local groups=$(find1 $cube_up_path -name '*\?') || fail

  begin_for group in $groups; doo 
    dep_name=${group##*/}
    target=$batch_up_path/$dep_name
    mkdir -p $target || fail
    batch_setup_x_deps up $group $target || fail
  end_for

  batch_setup_x_deps up $cube_up_path $batch_up_path || fail

end_function
handle_return

}

batch_setup_x_deps() {

local -r direction=$1    \
         cube_x_path=$2  \
         batch_x_path=$3
  
begin_function_flat

  local dep dep_name
  local deps=$(find1 $cube_x_path -not -name '*\?' | sort) || fail

  begin_for dep in $deps; doo
    ( batch_setup_x_deps_dep "$dep" ) || fail
  end_for

end_function_flat
handle_return

}

# should run in subshell since we are loading context
batch_setup_x_deps_dep() {

begin_function_flat

  local dep_dna=$dep/.dna \
    dep_cyto=$dep/.cyto

  if [[ ! -d $dep_cyto ]]; then
    prep_cube $dep || fail
  fi

  dep_name=${dep##*/}
  local real_dep=$(realpath $dep) \
    super_name=${cube_path##*/}

  if [[ $direction == up ]]; then
    if [[ ! -e $dep_cyto/down/$super_name ]]; then
      if [[ ! -d $dep_cyto/down ]]; then
        mkdir $dep_cyto/down || fail
      fi
      safe_link $cube_path $dep_cyto/down/$super_name || fail
    fi
  fi

  local batch_dep_name=$dep_name
  if [[ $batch_dep_name =~ ^[0-9]+-(.*) ]]; then
    batch_dep_name=${BASH_REMATCH[1]}
  fi
  if [[ ! -d $batch_x_path ]]; then
    err "$batch_x_path should already exist at this point in the code"
    fail1
  fi

  local target=$batch_x_path/$dep_name
  mkdir $target || fail

  local link_count=0 

  local $context_vars
  handle_member_override $batch_dep_name || fail
  load_context $dep || fail
  leaf_function=link_batch_dep \
    for_each_batch "${batch_dims[@]}" || fail

end_function_flat
handle_return

}

link_batch_dep() {

begin_function_flat

  local batch_node
  get_batch_node "${batch_values[@]}" || fail
  local batch_id
  get_batch_id "${batch_values[@]}" || fail

  update_batch_value_file || fail

  local x_batch=$real_dep/.cyto/batch$batch_node
  if [[ ! -d $x_batch ]]; then
    mkdir -p $x_batch || fail
  fi

  local link_name=${batch_dep_name}_$batch_id
  link_name=${link_name%_}
  safe_link $x_batch $target/$link_name || fail

  if [[ $direction == up ]]; then

    local up_down_path=$x_batch/down/$super_name/$batch_id
    up_down_path=${up_down_path%/}

    if [[ ! -e $up_down_path ]]; then
      if [[ ! -d $x_batch/down/$super_name ]]; then
        mkdir -p $x_batch/down/$super_name || fail
      fi
      safe_link $x_batch $up_down_path || fail
    fi

    if [[ $link_count == 0 ]]; then
      safe_link $x_batch $target/only || fail
    elif [[ $link_count == 1 ]]; then
      rm $target/only || fail
    fi

  fi

  let link_count++ || true

end_function_flat
handle_return

}

# input: $* = batch values in dim order
# output: batch_node = string path to batch from batch path
get_batch_node() {
local v i=0 d
batch_node=
for v in "$@"; do
  d=${batch_dims[$i]}
  get_sane_value "$v"
  v=$sane_value
  batch_node+=/dim/$d/$v
  let i++ || true
done
}

# input: $* = batch values in dim order
# output: batch_id = string batch id
get_batch_id() {
local v
batch_id=
for v in "$@"; do
  get_sane_value "$v"
  v=$sane_value
  batch_id+=_$v
done
batch_id=${batch_id#_}
}

handle_member_override() {
local -r dep=$1
local -r override_function=override_members_of_${dep//-/_}
if type $override_function &>/dev/null; then
  # used by the child/downstream cell to alter the members of an upstream cell
  $override_function || return 1
fi
return 0
}

# inputs: short_cell batch_path
# outputs: dim_string
gather_dims() {
local dimension dimension_plural
localize_dim_vars=
dim_string=
begin_function
  if [[ "$batch_dims" ]]; then
    begin_for dimension in "${batch_dims[@]}"; doo
      if [[ ! "$dimension" =~ ^[a-zA-Z0-9_]+$ ]]; then
        err "Invalid dimension name [$dimension]."
        err "Dimensions must only have alphanumeric or _ characters in it."
        fail1
      fi
      dimension_plural=${dimension}s
      localize_dim_vars+="local $dimension=\${$dimension:-} $dimension_plural=\${$dimension_plural:-}; "
      if [[ "${!dimension_plural:-}" ]]; then
        dim_string+="$dimension_plural=[ ${!dimension_plural:-} ] "
      else
        dim_string+="$dimension=${!dimension:-} "
      fi
    end_for
  fi
end_function
handle_return
}

does_cell_need_update() {
local batch_path=$1
  
trace $log_trace "Checking if update is needed for $short_cell"
begin_function

  needs_update=t local_inputs_changed=t maybe_deps_changed=t not_fresh=t always_update=f

  if [[ ! "$batch_out_path" ]]; then
    trace $log_trace "This cell is an event, will always update"
    always_update=t
    local_inputs_changed=f
  elif [[ ! -d "$batch_out_path" ]]; then
    trace $log_trace "Out path is missing, needs update"
  elif [[ "$batch_in_path" && "$batch_in_path" -nt "$status_path/updated" ]]; then
    trace $log_trace "Local changes were made, needs update"
  elif [[ $dna_path/context -nt $status_path/updated ]]; then
    trace $log_trace "context has changed, needs update"
  else
    local_inputs_changed=f
  fi

  if [[ "${fresh2:-}" ]]; then
    trace $log_trace "Fresh2 is set, so forcing update of upstream"
  elif [[ "$batch_up_path" && 
       ( "$batch_up_path" -nt "$status_path/updated" 
       || -f $status_path/upstream-changed 
       ) 
       ]]; then
    trace $log_trace "Upstream changes were made, needs update"
  else
    maybe_deps_changed=f
  fi

  if [[ "$batch_out_path" ]]; then
    if [[ $fresh == inf ]]; then
      not_fresh=f
    elif [[ $fresh != 0 ]]; then

      local fresh_seconds
      convert_to_seconds $fresh fresh_seconds || fail
      local fresh_cutoff=$((EPOCHSECONDS-fresh_seconds))
      local out_timestamp=
      if [[ -f $status_path/freshness ]]; then
        out_timestamp=$(date -r $status_path/freshness +%s)
      fi

      if [[ $ignore_fresh == f 
        && ( ! "$out_timestamp" || $out_timestamp -lt $fresh_cutoff )
        ]]; then

        trace $log_trace "Freshness requirement ($fresh) not met, needs update"

      else

        local min_upstream_freshness=inf

        if [[ ! -f $status_path/min-upstream-freshness ]]; then
          derive_min_upstream_freshness $batch_path || fail
          echo "min_upstream_freshness=$min_upstream_freshness" >$status_path/min-upstream-freshness || fail
        else
          source $status_path/min-upstream-freshness || fail
        fi

        if [[ $min_upstream_freshness != inf ]]; then
          fresh_cutoff=$((EPOCHSECONDS-min_upstream_freshness))
          if [[ $out_timestamp -lt $fresh_cutoff ]]; then
            trace $log_trace "Freshness requirement ($fresh) not met because of upstream, needs update"
          else
            not_fresh=f
          fi
        else
          not_fresh=f
        fi

      fi
    fi

  else
    not_fresh=f
  fi

  if [[ $maybe_deps_changed == f && $local_inputs_changed == f && $not_fresh == f && $always_update == f ]]; then
    needs_update=f
  fi

end_function
handle_return
}

# input: $1 (up_path of a cell to be analyzed)
# output: min_upstream_freshness
derive_min_upstream_freshness() {
local batch_path=$1
[[ ! "$batch_path" || ! -d "$batch_path" ]] && return 0
begin_function

  setup_cube_path_vars $batch_path || fail
  local default_fresh=inf \
        result

  if [[ -f $status_path/min-upstream-freshness ]]; then
    local prev=$min_upstream_freshness
    source $status_path/min-upstream-freshness || fail
    min $min_upstream_freshness $prev || fail
    min_upstream_freshness=$result
    succeed
  fi

  if [[ $default_fresh != inf ]]; then
    local default_fresh_seconds
    convert_to_seconds $default_fresh default_fresh_seconds || fail
    min $min_upstream_freshness $default_fresh_seconds || fail
    min_upstream_freshness=$result
  fi

  local group dep

  begin_for group in $(find1 $batch_up_path -name '*\?' -type d); doo or_fail
    begin_for dep in $(find1 $group -type d); doo or_fail
      derive_min_upstream_freshness_handle_group $dep || fail
    true; end_for
  true; end_for

  begin_for dep in $(find1 $batch_up_path -not -name '*\?' -type d); doo or_fail
    derive_min_upstream_freshness_handle_group $dep || fail
  true; end_for

  echo "min_upstream_freshness=$min_upstream_freshness" >$status_path/min-upstream-freshness || fail

end_function
handle_return
}

handle_cell_storage() {
trace $log_trace2 "Handling cell storage"
begin_function

  local storage_index var_name var_default storage_count=${#cell_storage[*]} \
    value update_value

  if [[ ! "$batch_in_path" ]]; then
    batch_in_path=$batch_path/in
    mkdir -p $batch_in_path || return 1
    for ((storage_index=0; storage_index < storage_count; storage_index+=2)); do
      var_name=${cell_storage[$storage_index]}
      var_default=${cell_storage[$((storage_index+1))]}
      if [[ "$var_default" ]]; then
        echo "$var_default" >$batch_in_path/$var_name || return 1
      fi
    done
  fi

  for ((storage_index=0; storage_index < storage_count; storage_index+=2)); do

    var_name=${cell_storage[$storage_index]}
    var_default=${cell_storage[$((storage_index+1))]}
    update_value=f
    eval "value=\${p_$var_name:-}"

    # TODO .safe var names should be encrypted
    local previous_value= new_value=
    if [[ -f $batch_in_path/$var_name ]]; then
      previous_value=$(<$batch_in_path/$var_name)
      new_value=$previous_value
    fi

    if [[ "$value" && "$previous_value" != "$value" ]]; then
      echo "$value" >$batch_in_path/$var_name || return 1
      new_value=$value
      touch $batch_in_path || return 1
    fi

    if [[ ! "$new_value" && "$var_default" ]]; then
      new_value=$var_default
    fi

    if [[ "$new_value" ]]; then
      eval "$var_name=\$new_value"
      eval "s_$var_name=\$new_value"
    else
      err "Required parameter $var_name is missing. Set it on the commandline."
      fail1
    fi

  done

end_function
handle_return

}

readonly path_vars='
batch_cyto_path
batch_in_path
batch_lock_path
batch_log_path
batch_out_path
batch_path
cube_cyto_path
cube_in_path
cube_lock_path
cube_log_path
cube_out_path
dim_path
dna_path
down_path
in_path
invalidate_path
key_path
measure_path
metric_path
out_path
req_path
short_cell
status_path
tmp_path
'

handle_static_subs() {
begin_function

  local subs_that_need_update=() locked_count=0
  for sub in $folders; do
    if folder_to_lock=$sub is_locked; then
      let locked_count++
    elif does_cell_have_request $sub; then
      subs_that_need_update+=( $sub )
    fi
  done

  local parallel=f count=${#subs_that_need_update[*]} \
    something_needs_update=t
  if [[ $count -gt 1 ]]; then
    if [[ $parallel_execution == t ]]; then
      parallel=t
      wait_for_low_load || fail
    fi
  elif [[ $count == 0 ]]; then
    something_needs_update=f
  fi

  if [[ $something_needs_update == t ]]; then
    local processes=
    for sub in ${subs_that_need_update[*]}; do
      if [[ $parallel == t ]]; then
        # recursive
        spawn_loop=once spawn_update_process $sub &
        processes+=" $!"
      else
        # recursive
        ( spawn_loop=once spawn_update_process $sub ) || fail
      fi
    done
  fi

  if [[ $locked_count -gt 0 ]]; then
    something_is_locked=t
  fi

end_function
handle_return
}

does_cube_have_request() {
if [[ "$req_path" ]]; then
  [[ "$(ls $req_path/new)" ]]
elif [[ "$cube_status_path" && -d "$cube_status_path" ]]; then
  [[ $cube_status_path/update_requested -nt $cube_status_path/updated ]]
else
  true  # if no tracking, then we always update
fi
}

does_cell_have_request() {
if [[ "$req_path" ]]; then
  [[ "$(ls $req_path/new)" ]]
else
  [[ $batch_status_path/update_requested -nt $batch_status_path/updated ]]
fi
}

gen_copy() {
begin_function
  if [[ "$batch_in_path" && "$batch_out_path" ]]; then
    local need_decrypt ofile file files=
    files+=" $(find -L $batch_in_path -name '*.safe' -type f)"
    begin_for ofile in $files; doo
      file=${ofile#$path/}
      file=${file%.safe}
      local parent_folder=${file%/*}
      if [[ "$parent_folder" && "$parent_folder" != "$file" ]]; then
        mkdir -p $batch_out_path.new/$parent_folder || fail
      fi
      if [[ -f $batch_out_path/$file && $batch_out_path/$file -nt $ofile ]]; then
        ln $batch_out_path/$file $batch_out_path.new/$file || fail
      else
        from="$ofile" to="$batch_out_path.new/$file" decrypt_file || fail
      fi
    end_for
    rsync -a --exclude='*.safe' $batch_in_path/ $batch_out_path.new/ || return 1
  fi
end_function
handle_return
}

get_archetype_folders() {
archetype_folders="$SIMPLETON_REPO/archetypes"
}

dna_new() {

local subject=$1

if [[ "$subject" == "$PWD" || -e "$subject" ]]; then
  err "You must specify a target path/file to create, which does not already exist."
  return 1
fi

begin_function

  subject=$(realpath $subject)
  get_cube "$subject"

  local type_default= what=
  if [[ "$cube" ]]; then
    if [[ "$subject" == "$cube/dim/"* ]]; then
      type_default=dim
      what=dim
    else
      incomplete "Don't know how to create this type of object yet: ${subject#$cube}"
    fi
  else
    type_default=standard
    what=cube
  fi

  local type=${type:-$type_default}
  trace 0 "Creating new $what ${subject#$PWD/} of type $type"
  if [[ $what == cube ]]; then
    mkdir -p $subject || fail
  fi
  get_archetype_folders || fail

  local type_folder_or_file=
  begin_for f in $archetype_folders; doo
    if [[ -e $f/$type ]]; then
      type_folder_or_file=$f/$type
      break
    fi
  end_for

  if [[ ! "$type_folder_or_file" ]]; then
    err "Couldn't find archetype $type in $archetype_folders"
    fail
  fi

  if [[ -d $type_folder_or_file ]]; then
    rsync -auq $type_folder_or_file/ $subject/ || fail
  else
    rsync -auq $type_folder_or_file $subject || fail
  fi

end_function
handle_return

}

dna_edit() {

local subject=$1      # which file to edit
local cube_path=      # may never be set, if we are editing a constant cell file

if [[ ! -f $subject ]]; then
  if [[ ! -d ${subject%/*} ]]; then
    err "Folder doesn't exist: ${subject%/*}"
    return 1
  fi
fi

local of_message= cube_found=t
get_cube_path $subject
if [[ ! "$cube_path" ]]; then
  cube_path=${subject%/*}
  cube_found=f
fi

local top_path= 
get_top_path $cube_path || return 1

local file=${subject##*/}
trace $log_info "Editing ${file} of cube ${cube_path#$top_path}"
begin_function
  
  local tmp_path
  focus_on $cube_path || fail
  local old_file=$subject
  local new_file=$subject.new
  local changed=f

  if [[ -f $new_file ]]; then
    err "$new_file already exists, delete that first if you want to edit $file"
    fail1
  fi

  local parent=${old_file%/*}
  if [[ ! -d $parent ]]; then
    mkdir -p $parent || fail
  fi

  if [[ $parent == *dim && ! -f $old_file ]]; then
    cp $SIMPLETON_REPO/template/dim $old_file || fail
  fi

  defer "rm $new_file"

  if [[ $file == *.safe ]]; then
    handle_secure_edit || fail
  else
    handle_insecure_edit || fail
  fi

end_function
failed && err "Editing $file failed"
handle_return
}

focus_on() {
local subject=$1
begin_function_flat
  prep_cube $subject
  setup_cube_path_vars $subject || fail
end_function_flat
handle_return
}

prep_cube() {
local subject=$1
begin_function_flat
  load_context $subject || fail
  if [[ ! -d $subject/.cyto ]]; then
    init_cube $subject || fail
  fi
end_function_flat
handle_return
}

get_cube_path() {
local subject=$1
cube_path=
if [[ -d $subject/.cyto || -d $subject/.dna ]]; then
  cube_path=$subject
else
  subject=${subject%/*}
  if [[ "$subject" =~ / ]]; then
    get_cube_path $subject
  fi
fi
}

handle_secure_edit() {
begin_function

  local unsafe_file=${file%.safe}
  local new_unsafe_file=$tmp_path/$unsafe_file.new
  local old_unsafe_file=$tmp_path/$unsafe_file.old

  if [[ -f $new_unsafe_file ]]; then
    err "$new_unsafe_file already exists, delete that first if you want to edit $file"
    fail1
  fi

  defer "rm $new_unsafe_file"
  defer "rm $old_unsafe_file"

  if [[ -f $old_file ]]; then
    from=$old_file to=$old_unsafe_file decrypt_file || fail
    cp $old_unsafe_file $new_unsafe_file || fail
  fi

  if [[ "$content" ]]; then
    echo "$content" >$new_unsafe_file || fail
  else
    $EDITOR $new_unsafe_file || fail
  fi

  if [[ -f $old_unsafe_file ]]; then
    if files_are_different $old_unsafe_file $new_unsafe_file >/dev/null; then
      changed=t
    else
      trace $log_trace "No change"
      rm $new_unsafe_file || fail
    fi
  else
    changed=t
  fi

  if [[ $changed == t ]]; then
    from=$new_unsafe_file to=$new_file encrypt_file || fail
    mv $new_file $old_file || fail
    update_modify_times "${new_file%/*}" "${current_cube}" || fail
  fi

end_function
handle_return
}

handle_insecure_edit() {
begin_function

  if [[ -f $old_file ]]; then
    cp $old_file $new_file || fail 
  fi

  if [[ "$content" ]]; then
    echo "$content" | trim_nl >$new_file || fail
  else
    $EDITOR $new_file || fail
  fi

  if [[ -f $old_file ]]; then
    if files_are_different $old_file $new_file >/dev/null; then
      changed=t
    else
      trace 0 "No change"
      rm $new_file || fail
    fi
  else
    changed=t
  fi

  if [[ $changed == t ]]; then
    mv $new_file $old_file || fail
    update_modify_times "${new_file%/*}" "$cube_path" || fail
  fi

end_function
handle_return
}

dna_link() {

local from=$1; shift
local to=$1

trace $log_info "Linking ${from#$top_path} to ${to#$top_path}"
begin_function

  if [[ $from == */ ]]; then
    from=$from${to##*/}
  fi

  if [[ $to == */ ]]; then
    to=$to${from##*/}
  fi

  if [[ -e $to || -L $to ]]; then
    if [[ -e $from ]]; then
      if [[ ${force:-f} == t ]]; then
        maybe rm -r $to || fail
      else
        err "Target cube already exists or a folder or link is already there."
        err "Delete it if you want to create it again, or set force=t"
        fail1
      fi
    elif [[ ! -L $to ]]; then # $from doesn't exist, attempt a reverse link
      trace $log_info "Reverse linking"
      maybe mv $to $from || fail
    else # $from doesn't exist, but $to is a link
      err "Attempting a reverse link when a link exists at the target."
      err "This only works if the target is a non-linked file or dir."
      fail1
    fi
  fi

  local abs_from=$(realpath -L $from)
  local abs_to=$(realpath -L $to)
  maybe ln -s $abs_from $abs_to || fail

  local cube cube_to cube_from
  get_cube ${abs_to%/*} 
  cube_to=$cube
  get_cube $abs_from 
  cube_from=$cube

  if [[ "$cube_to" && "$cube_from" ]]; then
    local to_without_cube=${abs_to#$cube_to/}
    local part=${to_without_cube%%/*}
    case $part in
      up)
        if [[ $cube_from != $abs_from ]]; then
          err "Only cubes can be linked into the up folder of a cube."
          err "$abs_from is not a cube"
          fail1
        fi
        local cube_to_name=${cube_to##*/}
        local down_link=$abs_from/down/$cube_to_name
        if [[ -e $down_link ]]; then
          maybe rm $down_link || fail
        elif [[ ! -d $abs_from/down ]]; then
          maybe mkdir -p $abs_from/down || fail
        fi
        maybe ln -s $cube_to $down_link || fail
      ;;
      down)
      ;;
      *)
        incomplete "part=$part"
      ;;
    esac
  fi

end_function
handle_return

}

test_mode=${test_mode:-serial}
run_test() {
local test_path=$1
testing_done=${testing_done:-f}
begin_function_flat
  if [[ -d "$test_path" ]]; then
    begin_for f in $(find1 $test_path); doo
      run_test $f || fail
      [[ $testing_done == t ]] && succeed
    end_for
  elif [[ -f "$test_path" && "$test_path" == */test-* ]]; then
    run_test_file $test_path || fail
  fi
end_function_flat
handle_return
}

run_test_file() {
local test_file=$1 \
      test_tmp_path=${test_tmp_path:-/tmp/cell-test/$$} \
      original_pwd=$PWD \
      failed=f \
      skipped=f
local short_file=${test_file#$PWD/}
trace 0 "Testing $short_file"
begin_function
  if [[ $test_mode == ask ]]; then
    local result
    prompt_ynq "Run test? " result 
    case $result in
      y)
        ;;
      n)
        skipped=t
        succeed
        ;;
      q)
        skipped=t
        testing_done=t
        succeed
        ;;
      *)
        err "Unknown result: $result"
        fail1
        ;;
    esac
  fi
  if [[ -e $test_tmp_path ]]; then
    rm -rf $test_tmp_path || fail
  fi
  mkdir -p $test_tmp_path || fail
  cd $test_tmp_path || fail
  let tests_found++
  local content=$(<$test_file)
  ( execute_test_content ) || failed=t
end_function

if [[ $failed == t ]]; then
  err "Test failed: $short_file"
  err "Test temp path: $test_tmp_path"
  let tests_failed++
elif [[ $skipped == t ]]; then
  let tests_skipped++
else
  let tests_passed++
fi

cd $original_pwd
handle_return
}

execute_test_content() {
begin_function_flat
  split_to_array content
  local previous_command= testing_done=f
  begin_for line in "${content[@]}"; doo
    if [[ "$line" ]]; then
      case "$line" in
        \$\ *)
          execute_previous || fail
          # allow for simpler escaped single quotes: '' instead of '\''
          line=${line//\'\'/\'\\\'\'}
          previous_command=${line#\$ }
        ;; 
        \#\ *)
          # ignore comments
        ;; 
        \ \ *)
          line=${line//\'\'/\'\\\'\'}
          previous_command+=$NL${line#  }
        ;; 
        *)
          err "Unknown test command:"
          err "$line"
          fail1
        ;;
      esac
    fi
    [[ $testing_done == t ]] && break
  end_for
  if [[ $testing_done == f ]]; then
    execute_previous || fail
  fi
end_function_flat
handle_return
}

execute_previous() {
if [[ "$previous_command" ]]; then
  trace -e $log_info "\$ ${previous_command//$NL/$NL  }"
  local result=y
  if [[ $test_mode == ask ]]; then
    prompt_ynq "Execute command? " result
  fi
  case $result in
    y)
      eval "$previous_command" || return 1
      ;;
    n)
      ;;
    q)
      testing_done=t
      ;;
    *)
      err "Invalid result: $result" 
      fail1
      ;;
  esac
  previous_command=
fi
return 0
}

# input must be a folder
setup_cube_path_vars() {
begin_function_flat

  if [[ ! "${top_path:-}" ]]; then
    get_top_path "$subject" || fail
  fi

  cube_path=$(realpath $1) \
    dna_path=$cube_path/.dna \
    cube_cyto_path=$cube_path/.cyto \
    short_cube=${cube_path#$top_path}

  if [[ ! -d $dna_path ]]; then

    cube_type=constant
    dna_path=

  else

    if [[ -d $dna_path/key ]]; then
      key_path=$dna_path/key
    else
      key_path=
    fi

  fi

  cube_up_path=$dna_path/up
  if [[ ! -d $cube_up_path ]]; then
    cube_up_path=
  fi

  cube_down_path=$cube_cyto_path/down
  if [[ ! -d $cube_down_path ]]; then
    cube_down_path=
  fi

  # context can override these as needed
  # should be a relative path
  in_path=${in_path:-}
  out_path=${out_path:-}

  if [[ "$in_path" ]]; then
    if [[ "$in_path" == . ]]; then
      cube_in_path=$cube_path
    else
      cube_in_path=$cube_path/$in_path
    fi
  fi

  if [[ "$out_path" ]]; then
    if [[ "$out_path" == . ]]; then
      cube_out_path=$cube_path
    else
      cube_out_path=$cube_path/$out_path
    fi
  fi

  cube_status_path=$cube_cyto_path/status
  if [[ ! -d $cube_status_path ]]; then
    cube_status_path=
  fi

  cube_lock_path=$cube_cyto_path/lock
  if [[ ! -d $cube_lock_path ]]; then
    cube_lock_path=
  fi

  cube_log_path=$cube_cyto_path/log
  if [[ ! -d $cube_log_path ]]; then
    cube_log_path=
  fi

  cube_debug_path=$cube_cyto_path/debug
  if [[ ! -d $cube_debug_path ]]; then
    cube_debug_path=
  fi

  req_path=$cube_cyto_path/req
  if [[ ! -d $req_path ]]; then
    req_path=
  fi

  # if there are dims, this will be overridden in setup_batch_path_vars
  batch_path=$cube_cyto_path/batch

end_function_flat
handle_return
}

get_top_path() {
local subject=$1
subject=${subject%%/.dna*}
subject=${subject%%/.cyto*}
local parent=${subject%/*}
if [[ -d $parent/.dna ]]; then
  if [[ ! -d $parent/.cyto ]]; then
    init_cube $parent || return 1
  fi
  # recursive
  get_top_path $parent || return 1
else
  top_path=$parent/
fi
return 0
}

# This is run if cube hasn't been initialized = missing .cyto folder
# Context should be loaded before this is run
init_cube() {
local subject=$1
begin_function_flat
  cube_cyto_path=$subject/.cyto
  mkdir $cube_cyto_path || fail
  local feature
  cube_lock_path=
  if [[ "${cube_features:-}" ]]; then
    begin_for feature in "${cube_features[@]}"; doo
      case $feature in
        req)
          mkdir -p $cube_cyto_path/$feature/new || fail
        ;;
        log)
          mkdir -p $cube_cyto_path/$feature || fail
        ;;
        *)
          err "Unknown feature $feature"
          fail1
        ;;
      esac
    end_for
  fi
  if [[ -d $subject/.dna ]]; then
    mkdir $cube_cyto_path/batch \
          $cube_cyto_path/status || fail
  fi
end_function_flat
handle_return
}

load_context() {
local subject=$1
last_context_loaded=${last_context_loaded:-}
[[ "$last_context_loaded" == $subject ]] && return 0
init_context || return 1
if [[ -f $subject/.dna/context ]]; then
  source $subject/.dna/context || return 1
fi
last_context_loaded=$subject
}

readonly context_vars='
batch_dims
cell_dims
'

# should be run before spawn update function
init_context() {

  # default_fresh:
  #   inf means infinite (never refresh based on time). 30s means refresh if it is older than 30 seconds.
  #   1w means refresh if it's older than a week.
  # high_volume_cell:
  #   does the cell have thousands of cells or more? If so we will use another folder level
  # ignore_fresh:
  #   whether freshness is used to determine if a cell needs to be updated
  # cell_storage:
  #   contains pairs of var_name/default values used to store data in this cell
  # shuffle_chance:
  #   chance out of 1000 of not following the computed strategy order
  # min_pause:
  #   number of ms to wait between cycles
  #   this number doubles each time there is nothing to do, until it reaches max_pause
  # cube_type:
  #   can be: constant info change
  #   constant means it just holds a fixed value that never changes
  #   info means it only fetches information 
  #   change means that it applies a change

  batch_dims= \
  cell_dims= \
  in_path= \
  in_paths= \
  out_path= \
  out_paths= \
  cube_in_path= \
  cube_out_path= \
  batch_in_path= \
  batch_out_path= \
  default_fresh=inf \
  require_fresh_greater_than= \
  retry_max=1 \
  retry_delay=1 \
  retry_scale=2 \
  cell_expiration= \
  high_volume_cell=f \
  ignore_fresh=f \
  default_strategies=crl \
  cell_storage=() \
  shuffle_chance=100 \
  force_update=${p_force_update:-f} \
  lock_timeout=${lock_timeout:-30} \
  prevalidate=f \
  postvalidate=f \
  generators=gen_copy \
  min_pause=250 \
  current_pause=250 \
  cube_type=info \
  max_pause=60000 \
  top_path=${top_path:-}

  # override this if there are parameter requirements that must be met before attempting to update the cell
  are_batch_params_valid() {
    return 0
  }

  # override this if there are some batch id combinations which are not valid even when
  # composed of valid dim members
  # returns 0 if it's not a valid combination of members
  skip_batch() {
    return 1
  }

  # this may be overridden to provide a custom cooldown calculation
  get_cooldown_delay() {
    [[ -z "${cooldown_delay:-}" ]] && cooldown_delay=1
    let cooldown_delay*=2
  }

  # override this function to implement custom update logic
  unset execute_update

}

# batch_id should be figured out before this, 
#   although it may be empty if no dims in this batch
#   each element should be expanded and validated beforehand
setup_batch_path_vars() {
begin_function_flat

  require_var cube_path cube_cyto_path

  # batch id is quite different than batch path, given new structure: .cyto/dim/env/e1...
  batch_path=$cube_cyto_path/batch
  batch_dna_path=$dna_path/batch
  batch_id=only
  batch_value_path=

  if [[ "${batch_values:-}" ]]; then
    local i d v
    batch_id=
    for ((i=0; i < ${#batch_values[*]}; i++)); do

      d=${batch_dims[$i]}
      if [[ ! "$d" ]]; then
        err "Invalid cube config: batch_values array has more elements than the number of batch_dims"
        fail1
      fi
      if [[ ! "$d" =~ ^[A-Za-z0-9_\.:\-]+$ ]]; then
        err "Invalid cube config: Bad dim name: $d"
        fail1
      fi

      get_sane_value "${batch_values[$i]}" || fail
      v=$sane_value

      local dim_part=/dim/$d/$v
      batch_path+=$dim_part
      batch_id+=${v}_
      batch_value_path+=/$v

    done
    batch_id=${batch_id%_}
  fi

  if [[ ! -d $batch_path ]]; then
    mkdir -p $batch_path || fail
  fi

  update_batch_value_file || fail

  if [[ "$cube_lock_path" ]]; then
    # Will be created when a lock on this batch is obtained
    batch_lock_path=$batch_path/lock
  else
    batch_lock_path=
  fi

  if [[ "$cube_status_path" ]]; then
    batch_status_path=$batch_path/status
    if [[ ! -d $batch_status_path ]]; then
      mkdir -p $batch_status_path || fail
    fi
  else
    batch_status_path=
  fi

  batch_tmp_path=$batch_path/tmp
  if [[ ! -d $batch_tmp_path ]]; then
    mkdir -p $batch_tmp_path || fail
  fi

  if [[ "$cube_log_path" ]]; then
    batch_log_path=$batch_path/log
    mkdir -p $batch_log_path || fail
  else
    batch_log_path=
  fi

  if [[ "$cube_debug_path" ]]; then
    batch_debug_path=$batch_path/debug
    mkdir -p $batch_debug_path || fail
  else
    batch_debug_path=
  fi

  if [[ "$cube_up_path" ]]; then
    batch_up_path=$batch_path/up
    # Don't create the up path here, but instead allow it to be created 
    #   inside of batch_update -> batch_setup_up
  else
    batch_up_path=
  fi

  if [[ "$cube_down_path" ]]; then
    batch_down_path=$batch_path/down
    # Created on demand
  else
    batch_down_path=
  fi

  if [[ "$in_path" ]]; then
    if [[ "$in_path" == . ]]; then
      batch_in_path=$cube_path$batch_value_path
    else
      batch_in_path=$cube_in_path$batch_value_path
    fi
    mkdir -p $batch_in_path || fail
  else
    batch_in_path=
  fi

  if [[ "$out_path" ]]; then
    if [[ "$out_path" == . ]]; then
      batch_out_path=$cube_path$batch_value_path
    else
      batch_out_path=$cube_out_path$batch_value_path
    fi
    mkdir -p $batch_out_path || fail
  else
    batch_out_path=
  fi

end_function_flat
handle_return
}

update_batch_value_file() {
begin_function_flat
  if [[ "${batch_values:-}" && ! -f $batch_path/batch_values ]]; then
    local v s='batch_values=( '
    for v in "${batch_values[@]}"; do
      s+="\"$v\" "
    done
    s+=')'
    echo "$s" >$batch_path/batch_values || fail
  fi
end_function_flat
handle_return
}

get_cube() {
cube_path=$1
[[ ${#cube_path} -lt 3 ]] && return 1
[[ -d $cube_path/.dna ]] && return 0
[[ -d $cube_path/.cyto ]] && return 0
get_cube ${cube_path%/*} || return 1
return 0
}

setup_tmp_path() {
if [[ ! "$tmp_path" ]]; then
  err "Missing tmp_path. Maybe you needed to run setup_cube_path_vars first"
  return 1
fi
if [[ ! -d $tmp_path ]]; then
  mkdir -p $tmp_path || return 1
fi
return 0
}

# params: $1 (subject)
# output: workspace
get_workspace() {
local subject=$1
workspace=
while [[ ${#subject} -gt 1 && $subject =~ / ]]; do
  if [[ "$subject" == "$top_path"/* ]]; then
    workspace=$subject
    break
  fi
  subject=${subject%/*}
done
[[ "$workspace" ]]
}

get_tmp_path() {
local current_cube=$1
if [[ -d $current_cube/tmp ]]; then
  tmp_path=$current_cube/tmp
elif [[ -d ~/tmp ]]; then
  tmp_path=~/tmp
else
  tmp_path=/tmp
fi
return 0
}

# inputs: from to tmp_path current_cube
# will write output to file at $to
decrypt_file() {

local from=$from
local to=$to
local tmp_path=$tmp_path
local key_path=$key_path
local user_private_key=${user_private_key:-~/.ssh/id_rsa}

trace $log_trace "Decrypting $from to $to"
begin_function

  if [[ ! -f "$user_private_key" ]]; then
    err "Private key is missing. Set path to it with user_private_key env var, or put it here: $user_private_key"
    err "You may create one using: ssh-keygen -mPEM"
    fail1
  fi

  if [[ ! "$tmp_path" ]]; then
    err "tmp_path must be set to a directory before calling decrypt_file."
    fail1
  fi

  if [[ ! -d $tmp_path ]]; then
    mkdir -p $tmp_path || fail
  fi

  if [[ ! -d "$key_path" ]]; then
    err "key_path must be set before calling decrypt_file"
    fail1
  fi

  if [[ ! -d $key_path ]]; then
    mkdir $key_path || fail
  fi

  if [[ ! -f "$key_path/key.$USER" ]]; then
    err "You don't have a key for this cube ($USER). Ask someone who does to add you. Existing keys:" 
    find -L $key_path -name "key.*" >&2
    fail1
  fi

  # extract the main key
  if ! openssl pkeyutl -decrypt -inkey $user_private_key -in "$key_path/key.$USER" -out $tmp_path/main; then
    err "Failed to decrypt main key." 
    fail1
  fi
  defer "rm $tmp_path/main"

  # decrypt the secret file
  if ! openssl enc -aes256 -pbkdf2 -in $from -out $to -d -pass file:$tmp_path/main; then 
    err "Failed to decrypt secret file." 
    fail1
  fi

end_function
handle_return

}

encrypt_file() {

local from=$from
local to=$to
local tmp_path=$tmp_path
local key_path=$key_path
local user_private_key=${user_private_key:-~/.ssh/id_rsa}

trace $log_trace "Encrypting $from to $to"
begin_function

  if [[ ! -f "$user_private_key" ]]; then
    err "Private key is missing. Set path to it with user_private_key env var, or put it here: $user_private_key"
    err "You may create one using: ssh-keygen -mPEM"
    fail1
  fi

  if [[ ! "$tmp_path" ]]; then
    err "tmp_path must be set to a directory before calling decrypt_file."
    fail1
  fi

  if [[ ! -d $tmp_path ]]; then
    mkdir -p $tmp_path || fail
  fi

  if [[ ! -d "$key_path" ]]; then
    err "key_path must be set before calling decrypt_file"
    fail1
  fi

  if [[ ! -d $key_path ]]; then
    mkdir $key_path || fail
  fi

  if [[ ! -f "$key_path/key.$USER" ]]; then

    local key_count=$(find -L $key_path -mindepth 1 -maxdepth 1 -name 'key.*' -type f | wc -l)

    if [[ $key_count -gt 0 ]]; then

      err "You don't have a key for this cube ($USER). Ask someone who does to add you. Existing keys:" 
      find -L $key_path -name "key.*" >&2
      fail1

    else

      trace $log_info "There are no keys for this cube yet. Will create a new key."

      # create a new main key
      if ! openssl rand -base64 40 >$tmp_path/main; then
        err "Failed to generate new main key."
        fail1
      fi
      defer "rm $tmp_path/main"

      # create a compatible public key from the user's private key
      if ! openssl pkey -in $user_private_key -out $tmp_path/public -pubout; then 
        err "Failed to convert private key to public key."
        fail1
      fi

      # encrypt main key with given user key
      if ! openssl pkeyutl -encrypt -pubin -inkey $tmp_path/public -in $tmp_path/main -out $key_path/key.$USER; then
        err "Failed to encrypt main key."
        fail1
      fi

    fi
  else 
    # extract the main key
    if ! openssl pkeyutl -decrypt -inkey $user_private_key -in $key_path/key.$USER -out $tmp_path/main; then
      err "Failed to decrypt main key." 
      fail1
    fi

    defer "rm $tmp_path/main"
  fi
    
  # encrypt the file with main key
  if ! openssl enc -aes256 -pbkdf2 -in $from -out $to -pass file:$tmp_path/main; then
    err "Failed to create new secret file."
    fail1
  fi

end_function
handle_return

}

fix_cube() {
local cube=$1
local cyto=$cube/.cyto
local dna=$cube/.dna
trace 0 "Fixing $cube"
begin_function
  fix_cube_folder $dna || fail
  fix_cube_folder $cyto || fail
  fix_cube_folder $cyto/status || fail
#  fix_cube_folder $cyto/req || fail
#  fix_cube_folder $cyto/req/new || fail
#  fix_cube_folder $cyto/req/processing || fail
#  fix_cube_folder $cyto/req/ready || fail
#  fix_cube_folder $cyto/req/done || fail
#  fix_cube_folder $cyto/req/all || fail
end_function
handle_return
}

fix_cube_folder() {
local folder=$1
if [[ ! -d $folder ]]; then
  tracex 0 mkdir $folder || return 1
fi
}

# this can be overridden by cubes which have non-default value format
show_value() {
local subject=$1
form=compact leaf_function=show_value_batch for_each_batch "${batch_dims[@]}" || fail
}

show_value_batch() {
if [[ -f $batch_path/value ]]; then
  cat $batch_path/value || return 1
else
  trace $log_info "No value for batch ${batch_id:-}"
fi
return 0
}

# dim vars and functions should be set before this is called
# will construct batch_values array with current set of values of the
#   batch dims, which can be used in branch or leaf functions
for_each_batch() {

local leaf_function=${leaf_function:-} \
  branch_function=${branch_function:-} \
  batch_values=( ) \
  multi_batch=${multi_batch:-f} \
  multi_cell=${multi_cell:-f} \
  remaining_batch_dims=( "$@" ) 

if [[ "${remaining_batch_dims:-}" ]]; then
  local finished=f
  batch_pivot "${remaining_batch_dims[@]}" || return 1
else
  if [[ "$leaf_function" ]]; then
    $leaf_function || return 1
  fi
  if [[ "$branch_function" ]]; then
    $branch_function || return 1
  fi
fi
}

# check if the dim exists before calling this
# other inputs: function
# *sometimes* runs as a subshell
batch_pivot() {

local -r remaining_batch_dims=( "$@" ) 
local -r dim=$remaining_batch_dims
local values=() \
  batch_values=( "${batch_values[@]}" ) \
  processes= 

begin_function_flat

  expand_values || fail
  batch_pivot_values || fail

end_function_flat
handle_return

}

# input: values (array)
batch_pivot_values() {
begin_function_flat

  local parallel=f \
        go_deeper=t 
  if [[ "${#values[*]}" -gt 1 ]]; then
    multi_batch=t
    if [[ "$parallel_execution" == t ]]; then
      parallel=t
      wait_for_low_load || fail
    fi
  fi

  local value sane_value processes= 

  batch_values+=( only )

  begin_for value in "${values[@]}"; doo

    eval "local $dim='$value' d_$dim='$value'"
    batch_values[-1]=$value

    if [[ "$branch_function" ]]; then
      $branch_function || fail
    fi

    if [[ $finished == t ]]; then
      break
    fi

    if [[ ${#remaining_batch_dims[*]} -gt 1 
       && $go_deeper == t
       ]]; then

      if [[ $parallel == t ]]; then
        # recursive
        batch_pivot "${remaining_batch_dims[@]:1}" &
        processes+=" $!"
      else
        # recursive
        batch_pivot "${remaining_batch_dims[@]:1}" || fail
      fi

    else

      if [[ "$leaf_function" ]]; then
        if [[ $parallel == t ]]; then
          $leaf_function &
          processes+=" $!"
        else
          $leaf_function || fail
        fi
      fi

    fi

  end_for

  wait_for_sub_processes || fail

end_function_flat
handle_return
}

get_sane_value() {
local -r value=$1
if [[ ${#value} -lt 40 && "$value" =~ ^[A-Za-z0-9_\.:\-]+$ ]]; then
  sane_value=$value
else
  hash=$(echo "$value" | cksum -a md5 | awk '{ print $4 }')
  sane_value=${hash:0:8}
fi
return 0
}

# input: parallel processes
wait_for_sub_processes() {
if [[ "$processes" ]]; then
  trace $log_info "Waiting for sub processes to complete"
  local process last_err_code= last_failed_process= rc
  for process in $processes; do
    trace $log_trace "Waiting for process $process"
    wait $process &>/dev/null; rc=$?
    if [[ $rc -gt 0 && $rc -lt 127 ]]; then
      if [[ ! "$last_err_code" ]]; then
        last_err_code=$rc
        last_failed_process=$process
      else
        trace $log_warn "Subprocess $process failed to terminate successfully"
        return 1
      fi
    fi
  done
  if [[ "$last_err_code" ]]; then
    if [[ "$last_err_code" == 1 ]]; then
      trace $log_warn "Subprocess $last_failed_process failed to terminate successfully"
      return 1
    fi
    return $last_err_code
  fi
  processes=
fi
return 0
}

# input: dim
# output: values 
expand_values() {
begin_function_flat

  local dims=${dim}s \
        new_value_list= new_values= new_value value \
        has_plural_expand_function=f

  values=( ${!dim:-} )

  type -t expand_members_$dim >/dev/null && has_plural_expand_function=t

  if [[ ! "${values:-}" ]]; then

    # handle plural dim
    values=( ${!dims:-} )

    if [[ ! "${values:-}" ]]; then

      # see if a default value is defined
      if [[ $has_plural_expand_function == t ]]; then
        value= expand_members_$dim || fail
      fi

      if [[ ! "${new_values:-}" ]]; then
        err "Missing value for dimension $dim"
        fail1
      fi

    else

      if [[ $has_plural_expand_function == t ]]; then
        local result=( )
        begin_for value in "${values[@]}"; doo
          value=$value expand_members_$dim || fail
          if [[ ! "${new_values:-}" ]]; then
            if [[ ! "${new_values:-}" ]]; then
              err "Dim $dims has invalid value '$value'"
              fail1
            fi
          fi
          result+=( "${new_values[@]}" )
        end_for
        new_values=( "${result[@]}" )
      else
        new_values=( "${values[@]}" )
      fi

    fi

    # remove duplicate values
    for new_value in "${new_values[@]}"; do
      if [[ ! $new_value_list =~ \ $new_value\  ]]; then
        new_value_list+=" $new_value "
      fi
    done

  else

    # handle singular dim
    if [[ "${#values[*]}" -gt 1 ]]; then
      err "Too many values for a singular dim $dim." \
        "Use plural dim $dims if you intend to have multiple values."
      fail1
    fi

    if [[ $has_plural_expand_function == t ]]; then
      value=$values expand_members_$dim || fail
      if [[ ! "$new_values" ]]; then
        err "Dim $dim has invalid value '$value'"
        fail1
      fi
      if [[ "${#new_values[*]}" -gt 1 ]]; then
        err "Too many values for a singular dim $dim." \
          "Use plural dim $dims if you intend to have multiple values."
        fail1
      fi
    else
      new_values=$values
    fi

    new_value_list+="$new_values"

  fi

  values=( $new_value_list )

end_function_flat
handle_return
}

wait_for_low_load() {
local cell_max_load=${cell_max_load:-10}
local cell_load_wait_timeout=${cell_load_wait_timeout:-600}
local current_load=$(uptime | sed -E 's/.*average: ([0-9]*).*/\1/')
if [[ $current_load -gt $cell_max_load ]]; then
  trace $log_warn "Load average is too high ($current_load > $cell_max_load)," \
    "waiting until things cool down first."
  local time_waited=0
  while [[ $current_load -gt $cell_max_load ]]; do
    current_load=$(uptime | sed -E 's/.*average: ([0-9]*).*/\1/')
    sleep 5; let time_waited+=5
    if [[ "$cell_load_wait_timeout" -gt 0 && $time_waited -ge $cell_load_wait_timeout ]]; then
      err "Timed out waiting for cpu load to be low enough. Aborting"
      return 1
    fi
  done
fi
return 0
}

is_cube() {
[[ -d "$1/.dna" ]]
}

is_inside_of_cube() {
local c=$1
if [[ $c == "$top_path"/* ]]; then
  while [[ $c == "$top_path"/* ]]; do
    if [[ -d $c/.dna ]]; then
      return 0
    fi
    c=${c%/*}
  done
else
  while [[ $c == /*/* ]]; do
    if [[ -d $c/.dna ]]; then
      return 0
    fi
    c=${c%/*}
  done
fi
return 1
}

# subject should be validated before calling this function
add_upstream() {
local -r subject=$1 link_name=${as:-${subject##*/}}
trace $log_info "Adding upstream dependency $subject to cube $to as $link_name"
begin_function
  ln -sf $subject $to/.dna/up/$link_name || fail
end_function
handle_return
}

